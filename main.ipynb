{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8a06afa",
   "metadata": {},
   "source": [
    "# Hand Gesture Recognition System  \n",
    "### Computer Vision Project using MediaPipe Hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f27f4383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "774b2dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_finger_extended(landmarks, finger_tip_id, finger_pip_id):\n",
    "    \"\"\"Check if a finger is extended based on landmark positions\"\"\"\n",
    "    tip = landmarks[finger_tip_id]\n",
    "    pip = landmarks[finger_pip_id]\n",
    "    return tip.y < pip.y  # Tip above PIP joint\n",
    "\n",
    "def is_thumb_extended(landmarks):\n",
    "    \"\"\"Special case for thumb - check horizontal extension\"\"\"\n",
    "    thumb_tip = landmarks[mp_hands.HandLandmark.THUMB_TIP]\n",
    "    thumb_ip = landmarks[mp_hands.HandLandmark.THUMB_IP]\n",
    "    thumb_mcp = landmarks[mp_hands.HandLandmark.THUMB_MCP]\n",
    "\n",
    "    palm_center_x = landmarks[mp_hands.HandLandmark.WRIST].x\n",
    "    return abs(thumb_tip.x - palm_center_x) > abs(thumb_mcp.x - palm_center_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96e85634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_gesture(hand_landmarks):\n",
    "    \"\"\"Rule-based gesture classification\"\"\"\n",
    "    landmarks = hand_landmarks.landmark\n",
    "\n",
    "    thumb_extended = is_thumb_extended(landmarks)\n",
    "    index_extended = is_finger_extended(landmarks,\n",
    "                                        mp_hands.HandLandmark.INDEX_FINGER_TIP,\n",
    "                                        mp_hands.HandLandmark.INDEX_FINGER_PIP)\n",
    "    middle_extended = is_finger_extended(landmarks,\n",
    "                                         mp_hands.HandLandmark.MIDDLE_FINGER_TIP,\n",
    "                                         mp_hands.HandLandmark.MIDDLE_FINGER_PIP)\n",
    "    ring_extended = is_finger_extended(landmarks,\n",
    "                                       mp_hands.HandLandmark.RING_FINGER_TIP,\n",
    "                                       mp_hands.HandLandmark.RING_FINGER_PIP)\n",
    "    pinky_extended = is_finger_extended(landmarks,\n",
    "                                        mp_hands.HandLandmark.PINKY_TIP,\n",
    "                                        mp_hands.HandLandmark.PINKY_PIP)\n",
    "\n",
    "    if not any([thumb_extended, index_extended, middle_extended, ring_extended, pinky_extended]):\n",
    "        return \"FIST\"\n",
    "    if all([thumb_extended, index_extended, middle_extended, ring_extended, pinky_extended]):\n",
    "        return \"OPEN_PALM\"\n",
    "    if thumb_extended and not any([index_extended, middle_extended, ring_extended, pinky_extended]):\n",
    "        return \"THUMBS_UP\"\n",
    "    if index_extended and middle_extended and not any([ring_extended, pinky_extended]):\n",
    "        return \"PEACE_SIGN\"\n",
    "    if index_extended and not any([middle_extended, ring_extended, pinky_extended]):\n",
    "        return \"POINTING\"\n",
    "    if index_extended and middle_extended and ring_extended and not pinky_extended:\n",
    "        return \"THREE\"\n",
    "    if index_extended and middle_extended and ring_extended and pinky_extended and not thumb_extended:\n",
    "        return \"FOUR\"\n",
    "\n",
    "    return \"UNKNOWN\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5897b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gesture_recognition(duration=60, show_landmarks=True):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    start_time = time.time()\n",
    "    current_gesture = \"NONE\"\n",
    "\n",
    "    print(\"Starting gesture recognition...\")\n",
    "    print(\"Press 'q' to quit\\n\")\n",
    "\n",
    "    while cap.isOpened() and (time.time() - start_time) < duration:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(rgb_frame)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                if show_landmarks:\n",
    "                    mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                gesture = classify_gesture(hand_landmarks)\n",
    "                if gesture != current_gesture:\n",
    "                    current_gesture = gesture\n",
    "                    print(\"Detected:\", current_gesture)\n",
    "        else:\n",
    "            if current_gesture != \"NONE\":\n",
    "                current_gesture = \"NONE\"\n",
    "                print(\"No hand detected\")\n",
    "\n",
    "        cv2.putText(frame, f\"Gesture: {current_gesture}\",\n",
    "                    (10, 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Hand Gesture Recognition\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b6c0280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gesture recognition...\n",
      "Press 'q' to quit\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alija\\Desktop\\School-Folder\\4337_Intro_Computer_Vision\\Hand-Gesture-Output\\.venv\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected: UNKNOWN\n",
      "Detected: THUMBS_UP\n",
      "No hand detected\n",
      "Detected: THUMBS_UP\n",
      "No hand detected\n",
      "Detected: THUMBS_UP\n",
      "No hand detected\n",
      "Detected: THREE\n",
      "Detected: OPEN_PALM\n",
      "Detected: PEACE_SIGN\n",
      "Detected: THREE\n",
      "Detected: FOUR\n",
      "Detected: OPEN_PALM\n",
      "Detected: THUMBS_UP\n",
      "Detected: FIST\n",
      "Detected: THUMBS_UP\n",
      "Detected: FIST\n",
      "Detected: THUMBS_UP\n",
      "Detected: FIST\n",
      "Detected: THUMBS_UP\n",
      "Detected: FIST\n",
      "Detected: UNKNOWN\n",
      "Detected: FIST\n",
      "No hand detected\n",
      "Detected: THUMBS_UP\n",
      "No hand detected\n",
      "Detected: UNKNOWN\n",
      "Detected: OPEN_PALM\n",
      "No hand detected\n",
      "Detected: FOUR\n",
      "Detected: THUMBS_UP\n",
      "Detected: OPEN_PALM\n",
      "Detected: THUMBS_UP\n",
      "Detected: FIST\n",
      "Detected: THUMBS_UP\n",
      "Detected: FIST\n",
      "Detected: THUMBS_UP\n",
      "Detected: FIST\n",
      "Detected: THUMBS_UP\n",
      "No hand detected\n",
      "Detected: FIST\n",
      "Detected: THREE\n",
      "Detected: FOUR\n",
      "Detected: UNKNOWN\n",
      "Detected: THREE\n",
      "Detected: POINTING\n",
      "Detected: FOUR\n",
      "Detected: FIST\n",
      "Detected: FOUR\n",
      "Detected: FIST\n",
      "Detected: PEACE_SIGN\n",
      "Detected: FIST\n",
      "Detected: THREE\n",
      "Detected: FIST\n",
      "Detected: THREE\n",
      "Detected: FIST\n",
      "Detected: THUMBS_UP\n",
      "Detected: FIST\n",
      "Detected: THUMBS_UP\n",
      "Detected: FIST\n",
      "Detected: UNKNOWN\n",
      "Detected: FIST\n",
      "Detected: UNKNOWN\n",
      "Detected: FIST\n",
      "Detected: UNKNOWN\n",
      "Detected: FIST\n",
      "Detected: UNKNOWN\n",
      "Detected: FIST\n",
      "Detected: UNKNOWN\n",
      "Detected: FIST\n",
      "No hand detected\n",
      "Detected: FIST\n",
      "Detected: UNKNOWN\n",
      "Detected: FIST\n",
      "Detected: UNKNOWN\n",
      "Detected: THUMBS_UP\n",
      "Detected: FIST\n",
      "Detected: THUMBS_UP\n",
      "Detected: POINTING\n",
      "Detected: PEACE_SIGN\n",
      "Detected: THUMBS_UP\n",
      "No hand detected\n",
      "Detected: THUMBS_UP\n",
      "Detected: FIST\n",
      "Detected: THUMBS_UP\n",
      "Detected: FIST\n",
      "Detected: THUMBS_UP\n",
      "Detected: FIST\n",
      "No hand detected\n",
      "Detected: THUMBS_UP\n",
      "Detected: UNKNOWN\n",
      "Detected: THUMBS_UP\n",
      "Detected: OPEN_PALM\n",
      "No hand detected\n",
      "Detected: THUMBS_UP\n",
      "Detected: OPEN_PALM\n",
      "Detected: POINTING\n",
      "Detected: PEACE_SIGN\n",
      "Detected: OPEN_PALM\n",
      "Detected: THREE\n",
      "Detected: POINTING\n",
      "Detected: PEACE_SIGN\n",
      "Detected: POINTING\n",
      "Detected: THREE\n",
      "Detected: OPEN_PALM\n",
      "Detected: UNKNOWN\n",
      "Detected: OPEN_PALM\n",
      "Detected: THREE\n",
      "Detected: PEACE_SIGN\n",
      "Detected: POINTING\n",
      "Detected: UNKNOWN\n",
      "Detected: OPEN_PALM\n",
      "Detected: THREE\n",
      "Detected: OPEN_PALM\n",
      "Detected: UNKNOWN\n",
      "Detected: OPEN_PALM\n",
      "Detected: UNKNOWN\n",
      "Detected: OPEN_PALM\n",
      "Detected: UNKNOWN\n",
      "Detected: THREE\n",
      "Detected: POINTING\n",
      "Detected: THUMBS_UP\n",
      "Detected: POINTING\n",
      "Detected: FIST\n",
      "Detected: POINTING\n",
      "Detected: PEACE_SIGN\n",
      "Detected: POINTING\n",
      "Detected: PEACE_SIGN\n",
      "Detected: THREE\n",
      "Detected: OPEN_PALM\n",
      "Detected: FOUR\n",
      "Detected: OPEN_PALM\n",
      "Detected: THUMBS_UP\n",
      "Detected: POINTING\n",
      "Detected: PEACE_SIGN\n",
      "Detected: THREE\n",
      "Detected: OPEN_PALM\n",
      "Detected: THUMBS_UP\n",
      "No hand detected\n",
      "Detected: POINTING\n",
      "Detected: OPEN_PALM\n",
      "Detected: THUMBS_UP\n",
      "Detected: FIST\n",
      "Detected: THUMBS_UP\n",
      "Detected: FIST\n",
      "Detected: THUMBS_UP\n",
      "Detected: PEACE_SIGN\n",
      "Detected: OPEN_PALM\n",
      "Detected: THREE\n",
      "Detected: OPEN_PALM\n",
      "Detected: THREE\n",
      "Detected: POINTING\n",
      "No hand detected\n",
      "Detected: THREE\n",
      "Detected: OPEN_PALM\n",
      "Detected: THREE\n",
      "Detected: PEACE_SIGN\n"
     ]
    }
   ],
   "source": [
    "run_gesture_recognition(duration=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f3df686",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GestureEvaluator:\n",
    "    \"\"\"Class for evaluating gesture recognition accuracy\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.evaluation_data = []\n",
    "        self.gesture_names = [\"FIST\", \"OPEN_PALM\", \"THUMBS_UP\", \"PEACE_SIGN\", \"POINTING\", \"THREE\",\"FOUR\"]\n",
    "\n",
    "    def collect_evaluation_data(self, gesture_name, num_samples=30,\n",
    "                                distance=\"medium\", background=\"clean\"):\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        samples_collected = 0\n",
    "        collecting = False\n",
    "\n",
    "        print(f\"\\nCollecting data for: {gesture_name}\")\n",
    "        print(f\"Distance: {distance}, Background: {background}\")\n",
    "        print(\"Press 's' to start, 'q' to quit\\n\")\n",
    "\n",
    "        while cap.isOpened() and samples_collected < num_samples:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = hands.process(rgb_frame)\n",
    "\n",
    "            predicted = \"NONE\"\n",
    "            confidence_score = 0.0\n",
    "\n",
    "            if results.multi_hand_landmarks:\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                    predicted = classify_gesture(hand_landmarks)\n",
    "                    confidence_score = results.multi_handedness[0].classification[0].score\n",
    "\n",
    "                    if collecting:\n",
    "                        self.evaluation_data.append({\n",
    "                            'timestamp': datetime.now().isoformat(),\n",
    "                            'ground_truth': gesture_name,\n",
    "                            'predicted': predicted,\n",
    "                            'correct': predicted == gesture_name,\n",
    "                            'distance': distance,\n",
    "                            'background': background,\n",
    "                            'confidence': confidence_score\n",
    "                        })\n",
    "                        samples_collected += 1\n",
    "\n",
    "            status = \"COLLECTING\" if collecting else \"READY - Press 's'\"\n",
    "            cv2.putText(frame, f\"{status} ({samples_collected}/{num_samples})\",\n",
    "                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "            cv2.putText(frame, f\"Ground Truth: {gesture_name}\",\n",
    "                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
    "\n",
    "            cv2.putText(frame, f\"Predicted: {predicted}\",\n",
    "                        (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "\n",
    "            cv2.imshow(\"Data Collection\", frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "            if key == ord('s'):\n",
    "                collecting = True\n",
    "                print(\"Started collecting...\")\n",
    "            elif key == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(f\"Collected {samples_collected} samples for {gesture_name}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea10a578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_evaluation(self, samples_per_condition=30):\n",
    "        distances = [\"close\", \"medium\", \"far\"]\n",
    "        backgrounds = [\"clean\", \"cluttered\"]\n",
    "\n",
    "        print(\"=\" * 50)\n",
    "        print(\" FULL GESTURE EVALUATION \")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        for gesture in self.gesture_names:\n",
    "            for distance in distances:\n",
    "                for background in backgrounds:\n",
    "                    print(f\"Testing {gesture} | {distance} | {background}\")\n",
    "                    self.collect_evaluation_data(\n",
    "                        gesture,\n",
    "                        num_samples=samples_per_condition,\n",
    "                        distance=distance,\n",
    "                        background=background\n",
    "                    )\n",
    "                    time.sleep(1)\n",
    "\n",
    "        self.save_results()\n",
    "\n",
    "def calculate_metrics(self):\n",
    "        if not self.evaluation_data:\n",
    "            print(\"No evaluation data found.\")\n",
    "            return\n",
    "\n",
    "        df = pd.DataFrame(self.evaluation_data)\n",
    "\n",
    "        overall_accuracy = df[\"correct\"].mean() * 100\n",
    "        gesture_accuracy = df.groupby(\"ground_truth\")[\"correct\"].mean() * 100\n",
    "        distance_accuracy = df.groupby(\"distance\")[\"correct\"].mean() * 100\n",
    "        background_accuracy = df.groupby(\"background\")[\"correct\"].mean() * 100\n",
    "\n",
    "        confusion = pd.crosstab(df[\"ground_truth\"], df[\"predicted\"],\n",
    "                                normalize=\"index\") * 100\n",
    "\n",
    "        print(\"\\nOverall Accuracy:\", round(overall_accuracy, 2), \"%\")\n",
    "        print(\"\\nGesture Accuracy:\\n\", gesture_accuracy)\n",
    "        print(\"\\nDistance Accuracy:\\n\", distance_accuracy)\n",
    "        print(\"\\nBackground Accuracy:\\n\", background_accuracy)\n",
    "        print(\"\\nConfusion Matrix:\\n\", confusion.round(2))\n",
    "\n",
    "        return {\n",
    "            \"overall_accuracy\": overall_accuracy,\n",
    "            \"gesture_accuracy\": gesture_accuracy.to_dict(),\n",
    "            \"distance_accuracy\": distance_accuracy.to_dict(),\n",
    "            \"background_accuracy\": background_accuracy.to_dict(),\n",
    "            \"confusion\": confusion.to_dict()\n",
    "        }\n",
    "\n",
    "def save_results(self, filename=\"evaluation_results.csv\"):\n",
    "        df = pd.DataFrame(self.evaluation_data)\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"Results saved to {filename}\")\n",
    "\n",
    "def load_results(self, filename=\"evaluation_results.csv\"):\n",
    "        df = pd.read_csv(filename)\n",
    "        self.evaluation_data = df.to_dict(\"records\")\n",
    "        print(f\"Loaded {len(self.evaluation_data)} samples from {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "980e1e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_robustness():\n",
    "    evaluator = GestureEvaluator()\n",
    "\n",
    "    print(\"Running quick robustness test...\")\n",
    "\n",
    "    test_cases = [\n",
    "        (\"FIST\", \"close\", \"clean\"),\n",
    "        (\"FIST\", \"far\", \"cluttered\"),\n",
    "        (\"OPEN_PALM\", \"medium\", \"clean\"),\n",
    "        (\"THUMBS_UP\", \"close\", \"cluttered\"),\n",
    "        (\"PEACE_SIGN\", \"far\", \"clean\"),\n",
    "        (\"POINTING\", \"medium\", \"cluttered\"),\n",
    "        (\"THREE\", \"close\", \"clean\"),\n",
    "        (\"FOUR\", \"far\", \"cluttered\"),\n",
    "    ]\n",
    "\n",
    "    for gesture, dist, bg in test_cases:\n",
    "        evaluator.collect_evaluation_data(\n",
    "            gesture, num_samples=10, distance=dist, background=bg\n",
    "        )\n",
    "\n",
    "    evaluator.calculate_metrics()\n",
    "    evaluator.save_results(\"robustness_test.csv\")\n",
    "\n",
    "# test_robustness()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
